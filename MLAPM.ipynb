{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVLLVn3+HX0it9g1aJhTTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mulat-K/Machine-Learning-Mastery-with-Python/blob/main/MLAPM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Algorithm Performance Metrics**"
      ],
      "metadata": {
        "id": "Um21_PYzqm14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Classi cation Metrics*"
      ],
      "metadata": {
        "id": "pjcOdoi9qw0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        " ˆ Classi cation Accuracy.\n",
        " ˆ Logarithmic Loss.\n",
        " ˆ Area Under ROC Curve.\n",
        " ˆ Confusion Matrix.\n",
        " ˆ Classi cation Report\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "azhmnwLvq2SP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classi cation Accuracy.**"
      ],
      "metadata": {
        "id": "J9eGzEheq_Ln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyaPFO-PqjS6",
        "outputId": "aa45908f-875b-4be1-d520-80cc4c1cd7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.772 (0.050)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/sample_data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pd.read_csv(filename, names=column_names, header=None)\n",
        "\n",
        "# Ensure all values are numeric and handle missing values\n",
        "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "# Split into input (X) and output (Y)\n",
        "X = dataframe.iloc[:, 0:8].values\n",
        "Y = dataframe.iloc[:, 8].values\n",
        "\n",
        "# Setup K-Fold Cross Validation\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Evaluate the model using K-Fold Cross Validation and classification accuracy\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(f\"Accuracy: {results.mean():.3f} ({results.std():.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logarithmic Loss.**"
      ],
      "metadata": {
        "id": "ws4eGC1XqljY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/sample_data/pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names, header=None)\n",
        "\n",
        "# Ensure all values are numeric and handle missing values\n",
        "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "# Split into input (X) and output (Y)\n",
        "X = dataframe.iloc[:, 0:8].values\n",
        "Y = dataframe.iloc[:, 8].values\n",
        "\n",
        "# Cross-validation setup with shuffle=True\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Use cross-validation to evaluate the model with LogLoss (negative log loss)\n",
        "scoring = 'neg_log_loss'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "# Print the LogLoss (negate the result as cross_val_score returns negative values)\n",
        "print(\"LogLoss: %.3f (%.3f)\" % (-results.mean(), results.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa4OGEvErH-h",
        "outputId": "95d4f95a-b474-4186-e5c1-2f2ca3d6335f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogLoss: 0.485 (0.057)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Area Under ROC Curve.**"
      ],
      "metadata": {
        "id": "3Tuh0WVqrI8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/sample_data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pd.read_csv(filename, names=column_names, header=None)\n",
        "\n",
        "# Ensure all values are numeric and handle missing values\n",
        "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "# Split into input (X) and output (Y)\n",
        "X = dataframe.iloc[:, 0:8].values\n",
        "Y = dataframe.iloc[:, 8].values\n",
        "\n",
        "# Setup K-Fold Cross Validation\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Evaluate the model using K-Fold Cross Validation and ROC AUC\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(f\"AUC: {results.mean():.3f} ({results.std():.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRooUkfCrNr_",
        "outputId": "94c52deb-cf6e-41c2-d502-11735d0c736b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.829 (0.047)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix.**"
      ],
      "metadata": {
        "id": "7glyhZBXrPn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/sample_data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pd.read_csv(filename, names=column_names, header=None)\n",
        "\n",
        "# Ensure all values are numeric and handle missing values\n",
        "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "# Split into input (X) and output (Y)\n",
        "X = dataframe.iloc[:, 0:8].values\n",
        "Y = dataframe.iloc[:, 8].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "# Generate and print confusion matrix\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw8Y-_wqrTdd",
        "outputId": "54fe4342-7174-4c67-8267-a43ae03cc9fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[142  20]\n",
            " [ 34  58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classi cation Report**"
      ],
      "metadata": {
        "id": "2GiLzhhFrWK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/sample_data/pima-indians-diabetes.data.csv'\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pd.read_csv(filename, names=column_names, header=None)\n",
        "\n",
        "# Ensure all values are numeric and handle missing values\n",
        "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "dataframe.dropna(inplace=True)\n",
        "\n",
        "# Split into input (X) and output (Y)\n",
        "X = dataframe.iloc[:, 0:8].values\n",
        "Y = dataframe.iloc[:, 8].values\n",
        "\n",
        "# Split the data into train and test sets\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "# Generate and print classification report\n",
        "report = classification_report(Y_test, predicted)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFRJJ4rDrXpl",
        "outputId": "c6f9b9ef-63c3-44ec-fb97-9d4865d3254a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.88      0.84       162\n",
            "         1.0       0.74      0.63      0.68        92\n",
            "\n",
            "    accuracy                           0.79       254\n",
            "   macro avg       0.78      0.75      0.76       254\n",
            "weighted avg       0.78      0.79      0.78       254\n",
            "\n"
          ]
        }
      ]
    }
  ]
}